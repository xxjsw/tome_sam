{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c280b112-ed3f-4103-98a9-b082a2532216",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "This notebook aims to do some experiments to show the impacts of **margin** from *pitome*.\n",
    "\n",
    "**Margin** *m* in Energy score for each node(token) works as a dynamic thresholding value that determines whether two tokens belong to the same object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46096a6b-5a68-4bbe-9603-f9d49a82b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "# change working directory otherwise accessing data folder fails\n",
    "os.chdir('..')\n",
    "from evaluate import EvaluateArgs, evaluate\n",
    "from tome_sam.utils.tome_presets import SAMToMeSetting, BSMToMe, ToMeConfig, PiToMe\n",
    "from flops import get_flops\n",
    "from tome_sam.build_tome_sam import SAM_CONFIGS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3da3fc-5750-4f9a-a504-1dbadf7d3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_RESULTS = pd.DataFrame({\n",
    "    \"model\": pd.Series(dtype=\"str\"),\n",
    "    \"dataset\": pd.Series(dtype=\"str\"),\n",
    "    \"image_size\": pd.Series(dtype=\"object\"),\n",
    "    \"tome_settings\": pd.Series(dtype=\"object\"),\n",
    "    \"mask_iou\": pd.Series(dtype=\"float\"),\n",
    "    \"boundary_iou\": pd.Series(dtype=\"float\"),\n",
    "    \"FLOPS\": pd.Series(dtype=\"float\"),\n",
    "    \"im/s\": pd.Series(dtype=\"float\"),\n",
    "    \"Experiment\": pd.Series(dtype=\"str\")\n",
    "})\n",
    "\n",
    "def update_experiment_results(*, result_df: pd.DataFrame, evaluate_args: EvaluateArgs, eval_results, flops: float, experiment: str):\n",
    "    new_row = { \"model\": evaluate_args.model_type,\n",
    "                \"dataset\": evaluate_args.dataset,\n",
    "                \"image_size\": evaluate_args.input_size,\n",
    "                \"tome_settings\": evaluate_args.tome_setting,\n",
    "                \"mask_iou\": eval_results[\"mask_iou\"],\n",
    "                \"boundary_iou\": eval_results[\"boundary_iou\"],\n",
    "                \"FLOPS\": flops[\"flops/img(image_encoder)\"],\n",
    "                \"im/s\": eval_results[\"im/s\"],\n",
    "                \"Experiment\": experiment\n",
    "              }\n",
    "    return pd.concat([result_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "def plot_heatmap(param1, param2, target_values, xlabel=\"param1\", ylabel=\"param2\", target_label=\"target_label\",\n",
    "                 cmap=\"RdYlGn\", annot=True, fmt=\".2f\"):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = sns.heatmap(\n",
    "        target_values,\n",
    "        xticklabels=param1,\n",
    "        yticklabels=param2,\n",
    "        cmap=cmap,\n",
    "        annot=annot,\n",
    "        fmt=fmt,\n",
    "        cbar_kws={'label': target_label},\n",
    "    )\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title('Heatmap')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_correlation_matrix(data, title=\"Correlation Matrix\", cmap=\"RdYlGn\", annot=True, fmt=\".2f\"):\n",
    "    correlation_matrix = data.corr()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        correlation_matrix,\n",
    "        annot=annot,\n",
    "        cmap=cmap,\n",
    "        fmt=fmt,\n",
    "        cbar_kws={'label': 'Correlation Coefficient'},\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_line_graph(x_values, y_values, title, x_label, y_label):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(x_values, y_values, marker='o', linestyle='-', color='blue', label='Line') \n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b78e86-37a8-44cf-9a52-2c7dd7842818",
   "metadata": {},
   "source": [
    "#### Pure SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29e593d6-a7d8-4e3a-a8d2-a28aee1fa3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture pure_sam\n",
    "evaluate_args = EvaluateArgs(\n",
    "    dataset=\"dis\",\n",
    "    output=\"\",\n",
    "    model_type=\"vit_b\",\n",
    "    checkpoint=\"checkpoints/sam_vit_b_01ec64.pth\",\n",
    "    device=\"mps\",\n",
    "    seed=0,\n",
    "    input_size=[1024, 1024],\n",
    "    batch_size=1,\n",
    "    multiple_masks=False,\n",
    "    tome_setting = None,\n",
    ")\n",
    "\n",
    "eval_results = evaluate(evaluate_args)\n",
    "flops_per_image = get_flops(evaluate_args)\n",
    "\n",
    "EXPERIMENT_RESULTS = update_experiment_results(result_df=EXPERIMENT_RESULTS, \n",
    "                                               evaluate_args=evaluate_args,\n",
    "                                               eval_results=eval_results, \n",
    "                                               flops=flops_per_image,\n",
    "                                               experiment='baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ddc69-873d-49cd-8aab-f1185998f014",
   "metadata": {},
   "source": [
    "#### Global Attention \n",
    "\n",
    "Only apply pitome with different margin r and  to ViT blocks which do global attention inside SAM image encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caeffa2d-9f33-467d-810b-b5744d0b82a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vit-b has in total 12 vit layers.\n",
      "Among all layers, it only calculates GLOBAL ATTENTION in [2, 5, 8, 11].\n"
     ]
    }
   ],
   "source": [
    "vit_b_config = SAM_CONFIGS[\"vit-b\"]\n",
    "print(f\"{vit_b_config.model_type} has in total {vit_b_config.depth} vit layers.\")\n",
    "print(f\"Among all layers, it only calculates GLOBAL ATTENTION in {vit_b_config.global_attn_indexes}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47afb768-4526-415a-95df-e422938a3581",
   "metadata": {},
   "source": [
    "Apply the same combinations of reduce rate **r** and **margin** onto all global attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea3e8174-b425-4502-b0d9-f573574a66f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Create valid dataloader with dataset dis ---\n",
      "------------------------------ valid --------------------------------\n",
      "--->>> dataset:  DIS5K-VD <<<---\n",
      "-im- DIS5K-VD ./data/DIS5K/DIS-VD/im :  470\n",
      "-gt- DIS5K-VD ./data/DIS5K/DIS-VD/gt :  470\n",
      "--- Valid dataloader with dataset dis created ---\n",
      "--- Create SAM vit_b with token merging in layers {2: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.0, alpha=1.0)), 5: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.0, alpha=1.0)), 8: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.0, alpha=1.0)), 11: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.0, alpha=1.0))} ---\n",
      "--- Start evaluation ---\n",
      "valid dataloader length: 470\n",
      "  [  0/470]  eta: 0:09:04  mask_iou: 0.7477 (0.7477)  boundary_iou: 0.5125 (0.5125)  time: 1.1596  data: 0.0531\n",
      "  [200/470]  eta: 0:05:54  mask_iou: 0.5691 (0.4796)  boundary_iou: 0.4713 (0.4090)  time: 1.1937  data: 0.0857\n",
      "  [400/470]  eta: 0:01:32  mask_iou: 0.4486 (0.4856)  boundary_iou: 0.4057 (0.4125)  time: 1.2955  data: 0.1079\n",
      "  [469/470]  eta: 0:00:01  mask_iou: 0.5901 (0.4857)  boundary_iou: 0.4431 (0.4129)  time: 1.1086  data: 0.0694\n",
      " Total time: 0:10:21 (1.3229 s / it)\n",
      "============================\n",
      "Averaged stats: mask_iou: 0.5901 (0.4857)  boundary_iou: 0.4431 (0.4129)\n",
      "--- Create valid dataloader with dataset dis ---\n",
      "------------------------------ valid --------------------------------\n",
      "--->>> dataset:  DIS5K-VD <<<---\n",
      "-im- DIS5K-VD ./data/DIS5K/DIS-VD/im :  470\n",
      "-gt- DIS5K-VD ./data/DIS5K/DIS-VD/gt :  470\n",
      "--- Valid dataloader with dataset dis created ---\n",
      "--- Create SAM vit_b with token merging in layers {2: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.0, alpha=1.0)), 5: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.0, alpha=1.0)), 8: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.0, alpha=1.0)), 11: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.0, alpha=1.0))} ---\n",
      "--- Start flop count analysis ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Create valid dataloader with dataset dis ---\n",
      "------------------------------ valid --------------------------------\n",
      "--->>> dataset:  DIS5K-VD <<<---\n",
      "-im- DIS5K-VD ./data/DIS5K/DIS-VD/im :  470\n",
      "-gt- DIS5K-VD ./data/DIS5K/DIS-VD/gt :  470\n",
      "--- Valid dataloader with dataset dis created ---\n",
      "--- Create SAM vit_b with token merging in layers {2: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.1, alpha=1.0)), 5: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.1, alpha=1.0)), 8: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.1, alpha=1.0)), 11: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.1, alpha=1.0))} ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siwei/Desktop/tome_sam/tome_sam/build_tome_sam.py:118: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start evaluation ---\n",
      "valid dataloader length: 470\n",
      "  [  0/470]  eta: 0:10:13  mask_iou: 0.7659 (0.7659)  boundary_iou: 0.5468 (0.5468)  time: 1.3062  data: 0.0634\n",
      "  [200/470]  eta: 0:05:39  mask_iou: 0.5793 (0.4796)  boundary_iou: 0.4831 (0.4093)  time: 1.1572  data: 0.0803\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 29\u001b[0m\n\u001b[1;32m      9\u001b[0m test_pitome_settings: SAMToMeSetting \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     global_layer_idx: ToMeConfig(\n\u001b[1;32m     11\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpitome\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m global_layer_idx \u001b[38;5;129;01min\u001b[39;00m vit_b_config\u001b[38;5;241m.\u001b[39mglobal_attn_indexes\n\u001b[1;32m     15\u001b[0m }\n\u001b[1;32m     16\u001b[0m evaluate_args \u001b[38;5;241m=\u001b[39m EvaluateArgs(\n\u001b[1;32m     17\u001b[0m dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdis\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m tome_setting \u001b[38;5;241m=\u001b[39m test_pitome_settings,\n\u001b[1;32m     27\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m iou_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m flops_per_image \u001b[38;5;241m=\u001b[39m get_flops(evaluate_args)\n\u001b[1;32m     31\u001b[0m EXPERIMENT_RESULTS \u001b[38;5;241m=\u001b[39m update_experiment_results(result_df\u001b[38;5;241m=\u001b[39mEXPERIMENT_RESULTS, tome_settings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ious\u001b[38;5;241m=\u001b[39miou_results, flops\u001b[38;5;241m=\u001b[39mflops_per_image)\n",
      "File \u001b[0;32m~/Desktop/tome_sam/evaluate.py:97\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     93\u001b[0m metric_logger \u001b[38;5;241m=\u001b[39m misc\u001b[38;5;241m.\u001b[39mMetricLogger(delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid dataloader length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(valid_dataloader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_val \u001b[38;5;129;01min\u001b[39;00m metric_logger\u001b[38;5;241m.\u001b[39mlog_every(valid_dataloader, \u001b[38;5;241m200\u001b[39m):\n\u001b[1;32m     98\u001b[0m     imidx, inputs, labels, shapes, labels_ori \u001b[38;5;241m=\u001b[39m data_val[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimidx\u001b[39m\u001b[38;5;124m\"\u001b[39m], data_val[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m], data_val[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m], data_val[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m], data_val[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mori_label\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    100\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Desktop/tome_sam/tome_sam/utils/misc.py:237\u001b[0m, in \u001b[0;36mMetricLogger.log_every\u001b[0;34m(self, iterable, print_freq, header, logger)\u001b[0m\n\u001b[1;32m    228\u001b[0m     log_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelimiter\u001b[38;5;241m.\u001b[39mjoin([\n\u001b[1;32m    229\u001b[0m         header,\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m space_fmt \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}/\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata: \u001b[39m\u001b[38;5;132;01m{data}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    235\u001b[0m     ])\n\u001b[1;32m    236\u001b[0m MB \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024.0\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024.0\u001b[39m\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    238\u001b[0m     data_time\u001b[38;5;241m.\u001b[39mupdate(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m end)\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m obj\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Desktop/tome_sam/tome_sam/utils/dataloader.py:253\u001b[0m, in \u001b[0;36mOnlineDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    251\u001b[0m gt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgt_path\u001b[39m\u001b[38;5;124m\"\u001b[39m][idx]\n\u001b[1;32m    252\u001b[0m im \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mimread(im_path)\n\u001b[0;32m--> 253\u001b[0m gt \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(gt\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    256\u001b[0m     gt \u001b[38;5;241m=\u001b[39m gt[:, :, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/skimage/io/_io.py:60\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     57\u001b[0m         plugin \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtifffile\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_or_url_context(fname) \u001b[38;5;28;01mas\u001b[39;00m fname:\n\u001b[0;32m---> 60\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcall_plugin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimread\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplugin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplugin_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(img, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/skimage/io/manage_plugins.py:217\u001b[0m, in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not find the plugin \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplugin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/skimage/io/_plugins/imageio_plugin.py:11\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(imageio_imread)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 11\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mimageio_imread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWRITEABLE\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     13\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/imageio/v3.py:54\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(uri, index, plugin, extension, format_hint, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m imopen(uri, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mplugin_kwargs) \u001b[38;5;28;01mas\u001b[39;00m img_file:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mimg_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcall_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/imageio/plugins/pillow.py:252\u001b[0m, in \u001b[0;36mPillowPlugin.read\u001b[0;34m(self, index, mode, rotate, apply_gamma, writeable_output, pilmode, exifrotate, as_gray)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# will raise IO error if index >= number of frames in image\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image\u001b[38;5;241m.\u001b[39mseek(index)\n\u001b[0;32m--> 252\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_transforms\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_gamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriteable_output\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(\n\u001b[1;32m    257\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    258\u001b[0m         rotate\u001b[38;5;241m=\u001b[39mrotate,\n\u001b[1;32m    259\u001b[0m         apply_gamma\u001b[38;5;241m=\u001b[39mapply_gamma,\n\u001b[1;32m    260\u001b[0m         writeable_output\u001b[38;5;241m=\u001b[39mwriteable_output,\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/imageio/plugins/pillow.py:333\u001b[0m, in \u001b[0;36mPillowPlugin._apply_transforms\u001b[0;34m(self, image, mode, rotate, apply_gamma, writeable_output)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;66;03m# pillow >= 10.1.0\u001b[39;00m\n\u001b[1;32m    331\u001b[0m         image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mconvert(desired_mode)\n\u001b[0;32m--> 333\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image\u001b[38;5;241m.\u001b[39mtell(), exclude_applied\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rotate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOrientation\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m meta:\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/PIL/Image.py:742\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 742\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRecursionError\u001b[39;00m)):\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/PIL/Image.py:802\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m encoder_args \u001b[38;5;241m==\u001b[39m ():\n\u001b[1;32m    800\u001b[0m     encoder_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m--> 802\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/PIL/ImageFile.py:293\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    292\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 293\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture global_attn_1\n",
    "\n",
    "r_values = list(np.arange(0.1, 0.6, 0.1))  # 0.1 <= r <= 0.5, step size 0.1\n",
    "margin_values = list(np.arange(0.0, 1.1, 0.1))  # 0.0 <= margin <= 1.0, step size\n",
    "alpha_value = 1.0 # alpha has a fixed value\n",
    "\n",
    "for r, margin in product(r_values, margin_values):\n",
    "    test_pitome_settings: SAMToMeSetting = {\n",
    "        global_layer_idx: ToMeConfig(\n",
    "            mode='pitome',\n",
    "            params=PiToMe(r=r, margin=margin, alpha=alpha_value)\n",
    "        )\n",
    "        for global_layer_idx in vit_b_config.global_attn_indexes\n",
    "    }\n",
    "    evaluate_args = EvaluateArgs(\n",
    "    dataset=\"dis\",\n",
    "    output=\"\",\n",
    "    model_type=\"vit_b\",\n",
    "    checkpoint=\"checkpoints/sam_vit_b_01ec64.pth\",\n",
    "    device=\"mps\",\n",
    "    seed=0,\n",
    "    input_size=[1024, 1024],\n",
    "    batch_size=1,\n",
    "    multiple_masks=False,\n",
    "    tome_setting = test_pitome_settings,\n",
    "    )\n",
    "    \n",
    "    eval_results = evaluate(evaluate_args)\n",
    "    flops_per_image = get_flops(evaluate_args)\n",
    "    EXPERIMENT_RESULTS = update_experiment_results(result_df=EXPERIMENT_RESULTS, \n",
    "                                                   evaluate_args=evaluate_args,\n",
    "                                                   eval_results=eval_results,\n",
    "                                                   flops=flops_per_image,\n",
    "                                                   experiment='same r and margin for all global attn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a3f312-b2e9-4b32-bd8a-d9d85e080c15",
   "metadata": {},
   "source": [
    "In the pitome paper, it also suggests to *dynamically* adjust **margin** according to the layer order. $m = 0.9 − 0.9 × l_i/l$, where $l_i$ is the current layer index and $l$ is the total number of encoder layers, indicating an increasing margin as tokens move to deeper layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43f9e668-d3e4-4f5c-983d-878ef3391306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Create valid dataloader with dataset dis ---\n",
      "------------------------------ valid --------------------------------\n",
      "--->>> dataset:  DIS5K-VD <<<---\n",
      "-im- DIS5K-VD ./data/DIS5K/DIS-VD/im :  470\n",
      "-gt- DIS5K-VD ./data/DIS5K/DIS-VD/gt :  470\n",
      "--- Valid dataloader with dataset dis created ---\n",
      "--- Create SAM vit_b with token merging in layers {2: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.75, alpha=1.0)), 5: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.525, alpha=1.0)), 8: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.30000000000000004, alpha=1.0)), 11: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.07500000000000007, alpha=1.0))} ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siwei/Desktop/tome_sam/tome_sam/build_tome_sam.py:118: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start evaluation ---\n",
      "valid dataloader length: 470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siwei/Desktop/tome_sam/tome_sam/tome_algo/pitome/merge.py:92: UserWarning: The operator 'aten::scatter_reduce.two_out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1729647065806/work/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  dst = dst.scatter_reduce(-2, dst_idx.expand(n, r, c), src, reduce=mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [  0/470]  eta: 0:26:35  mask_iou: 0.7843 (0.7843)  boundary_iou: 0.5698 (0.5698)  im/s: 0.3100 (0.3100)  time: 3.3937  data: 0.0566\n",
      "  [200/470]  eta: 0:05:27  mask_iou: 0.5834 (0.4828)  boundary_iou: 0.4677 (0.4106)  im/s: 1.1200 (1.0839)  time: 1.1553  data: 0.0868\n",
      "  [400/470]  eta: 0:01:27  mask_iou: 0.5295 (0.4879)  boundary_iou: 0.3887 (0.4129)  im/s: 1.1200 (1.0750)  time: 1.2319  data: 0.1019\n",
      "  [469/470]  eta: 0:00:01  mask_iou: 0.5906 (0.4875)  boundary_iou: 0.4451 (0.4128)  im/s: 1.1200 (1.0754)  time: 1.0970  data: 0.0658\n",
      " Total time: 0:09:46 (1.2477 s / it)\n",
      "============================\n",
      "Averaged stats: mask_iou: 0.5906 (0.4875)  boundary_iou: 0.4451 (0.4128)  im/s: 1.1200 (1.0754)\n",
      "--- Create valid dataloader with dataset dis ---\n",
      "------------------------------ valid --------------------------------\n",
      "--->>> dataset:  DIS5K-VD <<<---\n",
      "-im- DIS5K-VD ./data/DIS5K/DIS-VD/im :  470\n",
      "-gt- DIS5K-VD ./data/DIS5K/DIS-VD/gt :  470\n",
      "--- Valid dataloader with dataset dis created ---\n",
      "--- Create SAM vit_b with token merging in layers {2: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.75, alpha=1.0)), 5: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.525, alpha=1.0)), 8: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.30000000000000004, alpha=1.0)), 11: ToMeConfig(mode='pitome', params=PiToMe(r=0.1, margin=0.07500000000000007, alpha=1.0))} ---\n",
      "--- Start flop count analysis ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Create valid dataloader with dataset dis ---\n",
      "------------------------------ valid --------------------------------\n",
      "--->>> dataset:  DIS5K-VD <<<---\n",
      "-im- DIS5K-VD ./data/DIS5K/DIS-VD/im :  470\n",
      "-gt- DIS5K-VD ./data/DIS5K/DIS-VD/gt :  470\n",
      "--- Valid dataloader with dataset dis created ---\n",
      "--- Create SAM vit_b with token merging in layers {2: ToMeConfig(mode='pitome', params=PiToMe(r=0.2, margin=0.75, alpha=1.0)), 5: ToMeConfig(mode='pitome', params=PiToMe(r=0.2, margin=0.525, alpha=1.0)), 8: ToMeConfig(mode='pitome', params=PiToMe(r=0.2, margin=0.30000000000000004, alpha=1.0)), 11: ToMeConfig(mode='pitome', params=PiToMe(r=0.2, margin=0.07500000000000007, alpha=1.0))} ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siwei/Desktop/tome_sam/tome_sam/build_tome_sam.py:118: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start evaluation ---\n",
      "valid dataloader length: 470\n",
      "  [  0/470]  eta: 0:21:39  mask_iou: 0.7567 (0.7567)  boundary_iou: 0.5126 (0.5126)  im/s: 0.3800 (0.3800)  time: 2.7646  data: 0.0561\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 31\u001b[0m\n\u001b[1;32m     11\u001b[0m test_pitome_settings: SAMToMeSetting \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m     global_layer_idx: ToMeConfig(\n\u001b[1;32m     13\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpitome\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m global_layer_idx \u001b[38;5;129;01min\u001b[39;00m vit_b_config\u001b[38;5;241m.\u001b[39mglobal_attn_indexes\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     18\u001b[0m evaluate_args \u001b[38;5;241m=\u001b[39m EvaluateArgs(\n\u001b[1;32m     19\u001b[0m dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdis\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m tome_setting \u001b[38;5;241m=\u001b[39m test_pitome_settings,\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 31\u001b[0m iou_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m flops_per_image \u001b[38;5;241m=\u001b[39m get_flops(evaluate_args)\n\u001b[1;32m     33\u001b[0m EXPERIMENT_RESULTS \u001b[38;5;241m=\u001b[39m update_experiment_results(result_df\u001b[38;5;241m=\u001b[39mEXPERIMENT_RESULTS, \n\u001b[1;32m     34\u001b[0m                                                tome_settings\u001b[38;5;241m=\u001b[39mtest_pitome_settings, \n\u001b[1;32m     35\u001b[0m                                                eval_results\u001b[38;5;241m=\u001b[39meval_results, \n\u001b[1;32m     36\u001b[0m                                                flops\u001b[38;5;241m=\u001b[39mflops_per_image,\n\u001b[1;32m     37\u001b[0m                                                experiment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame r but dynamic margin for all global attn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/tome_sam/evaluate.py:123\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# batched output - list([dict(['masks', 'iou_predictions', 'low_res_logits'])])\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# masks - (image=1, masks per image, H, W)\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     t_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 123\u001b[0m     batched_output \u001b[38;5;241m=\u001b[39m \u001b[43mtome_sam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultimask_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     img_per_sec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batched_input)\u001b[38;5;241m/\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t_start), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    126\u001b[0m pred_masks \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray([output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasks\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu() \u001b[38;5;28;01mfor\u001b[39;00m\n\u001b[1;32m    127\u001b[0m                                     output \u001b[38;5;129;01min\u001b[39;00m batched_output]))\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/tome_sam/segment_anything/modeling/sam.py:98\u001b[0m, in \u001b[0;36mSam.forward\u001b[0;34m(self, batched_input, multimask_output)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03mPredicts masks end-to-end from provided images and prompts.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mIf prompts are not known in advance, using SamPredictor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m        to subsequent iterations of prediction.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m input_images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batched_input], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m image_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_record, curr_embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batched_input, image_embeddings):\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/tome_sam/tome_sam/tome_image_encoder.py:130\u001b[0m, in \u001b[0;36mToMeImageEncoderViT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    127\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embed\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 130\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneck(x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/tome_sam/tome_sam/tome_image_encoder.py:204\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    202\u001b[0m     H, W \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    203\u001b[0m     x, pad_hw \u001b[38;5;241m=\u001b[39m window_partition(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size)\n\u001b[0;32m--> 204\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# Reverse window partition\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tome_sam/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/tome_sam/tome_sam/tome_image_encoder.py:254\u001b[0m, in \u001b[0;36mEfficientAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtome_setting\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpitome\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    248\u001b[0m     x_merge, x_unmerge \u001b[38;5;241m=\u001b[39m pitome_vision(\n\u001b[1;32m    249\u001b[0m         metric\u001b[38;5;241m=\u001b[39mx, ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtome_setting\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mr,\n\u001b[1;32m    250\u001b[0m         margin\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtome_setting\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mmargin),\n\u001b[1;32m    251\u001b[0m         alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtome_setting\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39malpha,\n\u001b[1;32m    252\u001b[0m     )\n\u001b[0;32m--> 254\u001b[0m x_reduced \u001b[38;5;241m=\u001b[39m \u001b[43mx_merge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m _, N_reduced, _ \u001b[38;5;241m=\u001b[39m x_reduced\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# reshape x from (B*nHeads, N_reduced, C) to (B, N_reduced, C*nHeads)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/tome_sam/tome_sam/tome_algo/pitome/merge.py:92\u001b[0m, in \u001b[0;36mpitome_bsm.<locals>.merge\u001b[0;34m(x, mode)\u001b[0m\n\u001b[1;32m     90\u001b[0m unm \u001b[38;5;241m=\u001b[39m gather(src, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, index\u001b[38;5;241m=\u001b[39munm_idx\u001b[38;5;241m.\u001b[39mexpand(n, t1 \u001b[38;5;241m-\u001b[39m r, c))\n\u001b[1;32m     91\u001b[0m src \u001b[38;5;241m=\u001b[39m gather(src, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, index\u001b[38;5;241m=\u001b[39msrc_idx\u001b[38;5;241m.\u001b[39mexpand(n, r, c))\n\u001b[0;32m---> 92\u001b[0m dst \u001b[38;5;241m=\u001b[39m \u001b[43mdst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat([unm, dst], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%capture global_dynamic_attn\n",
    "\n",
    "r_values = list(np.arange(0.1, 0.6, 0.1))  # 0.1 <= r <= 0.5, step size 0.1\n",
    "alpha_value = 1.0 # alpha has a fixed value\n",
    "\n",
    "def get_dynamic_margin(current_layer_idx, total_layer_idx) -> float:\n",
    "    assert current_layer_idx <= total_layer_idx\n",
    "    return 0.9 - 0.9 * (current_layer_idx/total_layer_idx)\n",
    "    \n",
    "for r in r_values:\n",
    "    test_pitome_settings: SAMToMeSetting = {\n",
    "        global_layer_idx: ToMeConfig(\n",
    "            mode='pitome',\n",
    "            params=PiToMe(r=r, margin=get_dynamic_margin(global_layer_idx, vit_b_config.depth), alpha=alpha_value)\n",
    "        )\n",
    "        for global_layer_idx in vit_b_config.global_attn_indexes\n",
    "    }\n",
    "    evaluate_args = EvaluateArgs(\n",
    "    dataset=\"dis\",\n",
    "    output=\"\",\n",
    "    model_type=\"vit_b\",\n",
    "    checkpoint=\"checkpoints/sam_vit_b_01ec64.pth\",\n",
    "    device=\"mps\",\n",
    "    seed=0,\n",
    "    input_size=[1024, 1024],\n",
    "    batch_size=1,\n",
    "    multiple_masks=False,\n",
    "    tome_setting = test_pitome_settings,\n",
    "    )\n",
    "    \n",
    "    eval_results = evaluate(evaluate_args)\n",
    "    flops_per_image = get_flops(evaluate_args)\n",
    "    EXPERIMENT_RESULTS = update_experiment_results(result_df=EXPERIMENT_RESULTS, \n",
    "                                                   evaluate_args=evaluate_args,\n",
    "                                                   eval_results=eval_results, \n",
    "                                                   flops=flops_per_image,\n",
    "                                                   experiment='same r but dynamic margin for all global attn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5122df6f-2731-4ad2-ae1e-439ece6612ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
